{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe6464-24ac-4308-99be-007d7c2f0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver 실행\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "chrome_path = \"c://tmp//chromedriver.exe\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "driver = webdriver.Chrome(chrome_path,options=options)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11baa21-1fd7-4561-8c17-d626a73b58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "driver.get(\"https://www.google.com/search?q=%EC%9E%A5%EC%95%A0%EC%9D%B8+%EC%A3%BC%EC%B0%A8%EA%B5%AC%EC%97%AD&source=lmns&tbm=nws&bih=700&biw=1536&hl=ko&sa=X&ved=2ahUKEwjk8I7I5JD4AhU4RvUHHUgbCc8Q_AUoAnoECAEQAg\")\n",
    "time.sleep(2)\n",
    "\n",
    "title_list = []\n",
    "content_list = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        #제목\n",
    "        titles = soup.find('div','v7W49e').find_all('div','mCBkyc y355M JQe2Ld nDgy9d')\n",
    "        for title in titles:\n",
    "            title = re.sub('[^가-힣\\s]','',title.text)\n",
    "            title_list.append(title)\n",
    "\n",
    "        #내용\n",
    "        contents = soup.find('div','v7W49e').find_all('div','GI74Re nDgy9d')\n",
    "        for content in contents:\n",
    "            content = re.sub('[^가-힣\\s]','',content.text)\n",
    "            content_list.append(content)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    driver.find_element_by_id(\"pnnext\").click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfdc0b-e33a-4e03-9e44-b5aea7a38ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data={'title':title_list,'content':content_list})\n",
    "df.to_csv('googleCrawling.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
